{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1noyCBFQ4a6LfE3ee1pN49W4piHH0xX42",
      "authorship_tag": "ABX9TyONlNeBu6isVJy0Lu7f7PT2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LesterYe/BAGLS-Image-Segmentation/blob/main/file_io.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC07LRKEb4TJ",
        "outputId": "cd04e541-7b5c-4db1-9f83-c015a0d6663a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "tnNiCUrklVQp"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download train and test dataset into Colab virtual drive"
      ],
      "metadata": {
        "id": "vyySapqylw0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Train dataset\n",
        "!wget https://zenodo.org/record/3762320/files/training.zip\n",
        "\n",
        "# Download Test dataset\n",
        "!wget https://zenodo.org/record/3762320/files/test.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unQLHd9DlXDU",
        "outputId": "9157cfbb-27f5-45ba-a4ac-6b1d7ea80422"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-04 15:58:09--  https://zenodo.org/record/3762320/files/training.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3533810759 (3.3G) [application/octet-stream]\n",
            "Saving to: ‘training.zip’\n",
            "\n",
            "training.zip        100%[===================>]   3.29G  29.1MB/s    in 1m 55s  \n",
            "\n",
            "2022-12-04 16:00:06 (29.2 MB/s) - ‘training.zip’ saved [3533810759/3533810759]\n",
            "\n",
            "--2022-12-04 16:00:06--  https://zenodo.org/record/3762320/files/test.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 207236572 (198M) [application/octet-stream]\n",
            "Saving to: ‘test.zip’\n",
            "\n",
            "test.zip            100%[===================>] 197.64M  22.0MB/s    in 2m 59s  \n",
            "\n",
            "2022-12-04 16:03:06 (1.10 MB/s) - ‘test.zip’ saved [207236572/207236572]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Zip File"
      ],
      "metadata": {
        "id": "CB9eIUXdl_De"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Zip Files\n",
        "files = ['training', 'test']\n",
        "for file in files:\n",
        "  zip_file = file + '.zip'\n",
        " \n",
        "  try:\n",
        "    with zipfile.ZipFile(zip_file) as z:\n",
        "      z.extractall(f'./{file}')\n",
        "      print(f'Extracted all {zip_file} files')\n",
        "  except:\n",
        "    print('Invalid file')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9hQ9pzKldfH",
        "outputId": "9ce79f2e-7757-4245-afc7-2380d5df19e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted all\n",
            "Extracted all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make directory"
      ],
      "metadata": {
        "id": "G_OgQ61bGt8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.getcwd()"
      ],
      "metadata": {
        "id": "sknvr1RaG3TK"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1_path = os.path.join(path, 'dataset1')\n",
        "normal_classes_path = os.path.join(dataset1_path, 'normal')\n",
        "abnormal_classes_path = os.path.join(dataset1_path, 'abnormal')\n",
        "\n",
        "try:\n",
        "  os.makedirs(normal_classes_path)\n",
        "  os.makedirs(abnormal_classes_path)\n",
        "  print(f'Directory {normal_classes_path} created')\n",
        "  print(f'Directory {abnormal_classes_path} created') \n",
        "\n",
        "except FileExistsError:\n",
        "  print(\"Directories already exist.\")\n",
        "  # if you want to delete the existing dataset\n",
        "  # removing directory\n",
        "  shutil.rmtree(dataset1_path)\n",
        "  os.makedirs(normal_classes_path)\n",
        "  os.makedirs(abnormal_classes_path)\n",
        "  print(f'Directory {normal_classes_path} created')\n",
        "  print(f'Directory {abnormal_classes_path} created') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roN-ydEGGu0g",
        "outputId": "990ef874-636e-4687-ab06-9aeefa8c683d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directories already exist.\n",
            "Directory /content/dataset1/normal created\n",
            "Directory /content/dataset1/abnormal created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset1_path = os.path.join(path, 'testset1')\n",
        "normal_classes_path = os.path.join(testset1_path, 'normal')\n",
        "abnormal_classes_path = os.path.join(testset1_path, 'abnormal')\n",
        "\n",
        "try:\n",
        "  os.makedirs(normal_classes_path)\n",
        "  os.makedirs(abnormal_classes_path)\n",
        "  print(f'Directory {normal_classes_path} created')\n",
        "  print(f'Directory {abnormal_classes_path} created') \n",
        "\n",
        "except FileExistsError:\n",
        "  print(\"Directories already exist.\")\n",
        "  # if you want to delete the existing dataset\n",
        "  # removing directory\n",
        "  shutil.rmtree(testset1_path)\n",
        "  os.makedirs(normal_classes_path)\n",
        "  os.makedirs(abnormal_classes_path)\n",
        "  print(f'Directory {normal_classes_path} created')\n",
        "  print(f'Directory {abnormal_classes_path} created')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yre_9Mb1WZDQ",
        "outputId": "85a38cfe-1a87-4135-b87f-99fb1e554240"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directories already exist.\n",
            "Directory /content/testset1/normal created\n",
            "Directory /content/testset1/abnormal created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read file"
      ],
      "metadata": {
        "id": "NKQOaqhV8wjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_types = ['test', 'training']\n",
        "for dataset_type in dataset_types:\n",
        "  if dataset_type == 'test':\n",
        "    dataset_len = 3500\n",
        "    normal_classes_path = os.path.join(testset1_path, 'normal')\n",
        "    abnormal_classes_path = os.path.join(testset1_path, 'abnormal')\n",
        "  elif dataset_type == 'training':\n",
        "    dataset_len = 55750\n",
        "    normal_classes_path = os.path.join(dataset1_path, 'normal')\n",
        "    abnormal_classes_path = os.path.join(dataset1_path, 'abnormal')\n",
        "  \n",
        "  count = 0\n",
        "  for i in tqdm(range(dataset_len)):\n",
        "  # for i in range(dataset_len):\n",
        "    meta_filepath = os.path.join(dataset_type, dataset_type, str(i)+'.meta')\n",
        "    with open(meta_filepath) as f:\n",
        "      lines = f.readlines()\n",
        "    status_str = lines[13]\n",
        "    # print(status_str)\n",
        "    # print(status_str[32:-3])\n",
        "    status = status_str[32:-3]\n",
        "    img_name = str(i)+'.png'\n",
        "\n",
        "    if status == 'healthy':\n",
        "      # print(f'Class {status} is saved as normal')\n",
        "      destination = os.path.join(normal_classes_path, img_name)\n",
        "    elif status == '' or status == 'functional' or status[:4] == 'None':\n",
        "      # print(f'Class {status} will not be saved')\n",
        "      count+=1\n",
        "      continue\n",
        "    else:\n",
        "      # print(f'Class {status} is saved as abnormal')\n",
        "      destination = os.path.join(abnormal_classes_path, img_name)\n",
        "\n",
        "    ## Copy contents from source to destination ##\n",
        "    source = os.path.join(dataset_type, dataset_type, img_name)\n",
        "    try:\n",
        "      shutil.copy(source, destination)\n",
        "      # pass\n",
        "      # print(\"File copied successfully.\")\n",
        "    \n",
        "    # If source and destination are same\n",
        "    except shutil.SameFileError:\n",
        "      print(\"Source and destination represents the same file.\")\n",
        "      print(f'Source: {source} Destination: {destination}')\n",
        "\n",
        "    # if i == 450:\n",
        "    #   break\n",
        "  print(f'\\nNumber of images not saved for {dataset_type}: {count}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rqu8XnJD5ZqC",
        "outputId": "652531a4-52ff-4d9f-8d8a-f11e230ad259"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3500/3500 [00:02<00:00, 1440.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of images not saved for test: 1200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55750/55750 [00:58<00:00, 953.89it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of images not saved for training: 3100\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(r'training/training/36.meta','r') as f:\n",
        "  print(f.read())\n",
        "#   arr = f.readlines()\n",
        "# status_str = arr[13]\n",
        "# print(status_str)\n",
        "# print(status_str[32:-3])\n",
        "# status = status_str[32:-3]\n",
        "# if status == 'healthy':\n",
        "#   print(f'Class {status} is saved under normal')\n",
        "# elif status == 'other' or status == 'unknown status':\n",
        "#   print(f'Class {status} will not be saved')\n",
        "# else:\n",
        "#   print(f'Class {status} is saved under abnormal')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL9lUioq9piv",
        "outputId": "050a0b8e-b5b1-4c6a-dfe4-71a20622da66"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['{\\n', '    \"Video Id\": 131,\\n', '    \"Camera\": \"Phantom v210\",\\n', '    \"Sampling rate (Hz)\": 3000,\\n', '    \"Video resolution (px, HxW)\": [\\n', '        352,\\n', '        208\\n', '    ],\\n', '    \"Color\": false,\\n', '    \"Endoscope orientation\": null,\\n', '    \"Endoscope application\": \"\",\\n', '    \"Age range (yrs)\": \"\",\\n', '    \"Subject sex\": \"\",\\n', '    \"Subject disorder status\": \"\",\\n', '    \"Segmenter\": 1,\\n', '    \"Post-processed\": 2\\n', '}']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zip datasets and save in your Google Drive"
      ],
      "metadata": {
        "id": "Co0zDA6eVvbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Check Directory: {os.listdir()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWzzDO38fDul",
        "outputId": "3d82891b-ec68-4efe-851e-53f0e8380249"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check Directory: ['.config', 'dataset1', 'test', '.ipynb_checkpoints', 'drive', 'training.zip', 'test.zip', 'training', 'testset1', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r -q dataset1.zip dataset1\n",
        "!zip -r -q testset1.zip testset1"
      ],
      "metadata": {
        "id": "WmqlXLC4fPPW"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change this to your gdrive directory**"
      ],
      "metadata": {
        "id": "524VpSQcg4ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive_proj_dir = '/content/drive/MyDrive/BAGLS-Image-Segmentation/'\n",
        "dataset1zip_newpath = gdrive_proj_dir + 'dataset1.zip'\n",
        "testset1zip_newpath = gdrive_proj_dir + 'testset1.zip'"
      ],
      "metadata": {
        "id": "3AzEj_PnhGbS"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp dataset1.zip '{dataset1zip_newpath}'\n",
        "!cp testset1.zip '{testset1zip_newpath}'"
      ],
      "metadata": {
        "id": "gGmm_6Zhf670"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bNI5jwhoka4C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}